{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:13:46.891448Z","iopub.execute_input":"2023-11-11T17:13:46.891786Z","iopub.status.idle":"2023-11-11T17:13:54.282982Z","shell.execute_reply.started":"2023-11-11T17:13:46.891758Z","shell.execute_reply":"2023-11-11T17:13:54.281886Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.6.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.61.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.8)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.5)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom transformers import BertTokenizer, TFBertModel\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Dropout, GlobalMaxPooling1D, Bidirectional,Conv1D,MaxPooling1D,Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:13:54.284953Z","iopub.execute_input":"2023-11-11T17:13:54.285257Z","iopub.status.idle":"2023-11-11T17:13:54.303198Z","shell.execute_reply.started":"2023-11-11T17:13:54.285225Z","shell.execute_reply":"2023-11-11T17:13:54.302509Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:13:54.304964Z","iopub.execute_input":"2023-11-11T17:13:54.305232Z","iopub.status.idle":"2023-11-11T17:13:54.948513Z","shell.execute_reply.started":"2023-11-11T17:13:54.305205Z","shell.execute_reply":"2023-11-11T17:13:54.947603Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nle=preprocessing.LabelEncoder()\ny=le.fit_transform(df['sentiment'])","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:13:54.951051Z","iopub.execute_input":"2023-11-11T17:13:54.951333Z","iopub.status.idle":"2023-11-11T17:13:54.971481Z","shell.execute_reply.started":"2023-11-11T17:13:54.951306Z","shell.execute_reply":"2023-11-11T17:13:54.970671Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train, df_test,y_train,y_test= train_test_split(df,y,test_size = 0.20, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:13:54.972587Z","iopub.execute_input":"2023-11-11T17:13:54.972871Z","iopub.status.idle":"2023-11-11T17:13:55.020057Z","shell.execute_reply.started":"2023-11-11T17:13:54.972844Z","shell.execute_reply":"2023-11-11T17:13:55.019246Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#Removes Punctuations\ndef remove_punctuations(data):\n    punct_tag=re.compile(r'[^\\w\\s]')\n    data=punct_tag.sub(r'',data)\n    return data\n\n#Removes HTML syntaxes\ndef remove_html(data):\n    html_tag=re.compile(r'<.*?>')\n    data=html_tag.sub(r'',data)\n    return data\n\n#Removes URL data\ndef remove_url(data):\n    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n    data=url_clean.sub(r'',data)\n    return data\n\n#Removes Emojis\ndef remove_emoji(data):\n    emoji_clean= re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    data=emoji_clean.sub(r'',data)\n    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n    data=url_clean.sub(r'',data)\n    return data\n\ndf_train['review'] = df_train['review'].apply(lambda z: remove_punctuations(z))\ndf_train['review'] = df_train['review'].apply(lambda z: remove_html(z))\ndf_train['review'] = df_train['review'].apply(lambda z: remove_url(z))\ndf_train['review'] = df_train['review'].apply(lambda z: remove_emoji(z))\n\ndf_test['review'] = df_test['review'].apply(lambda z: remove_punctuations(z))\ndf_test['review'] = df_test['review'].apply(lambda z: remove_html(z))\ndf_test['review'] = df_test['review'].apply(lambda z: remove_url(z))\ndf_test['review'] = df_test['review'].apply(lambda z: remove_emoji(z))","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:13:55.024531Z","iopub.execute_input":"2023-11-11T17:13:55.024817Z","iopub.status.idle":"2023-11-11T17:14:04.295511Z","shell.execute_reply.started":"2023-11-11T17:13:55.024779Z","shell.execute_reply":"2023-11-11T17:14:04.294544Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = TFBertModel.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:14:04.297011Z","iopub.execute_input":"2023-11-11T17:14:04.297382Z","iopub.status.idle":"2023-11-11T17:14:20.262708Z","shell.execute_reply.started":"2023-11-11T17:14:04.297343Z","shell.execute_reply":"2023-11-11T17:14:20.261868Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa94bed85a2c40898e352183240b0823"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df4aea8d95a4b96bb881ba281c76e56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e3fe23cb1a4c6d8b07c3ac8dcfdb59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aef4c3351b64b56bd17eddb0431d15e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/536M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8b76f876f60405fa7705c671ff56490"}},"metadata":{}},{"name":"stderr","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Encoding ","metadata":{}},{"cell_type":"code","source":"# Tokenize text data\nMAX_LEN = 128\nX_train_tokenized = tokenizer.batch_encode_plus(\n    df_train['review'].tolist(),\n    max_length=MAX_LEN,\n    padding='max_length',\n    truncation=True,\n    return_attention_mask=True,\n    return_token_type_ids=False\n)\nX_test_tokenized = tokenizer.batch_encode_plus(\n    df_test['review'].tolist(),\n    max_length=MAX_LEN,\n    padding='max_length',\n    truncation=True,\n    return_attention_mask=True,\n    return_token_type_ids=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:14:20.264676Z","iopub.execute_input":"2023-11-11T17:14:20.264964Z","iopub.status.idle":"2023-11-11T17:21:22.504017Z","shell.execute_reply.started":"2023-11-11T17:14:20.264929Z","shell.execute_reply":"2023-11-11T17:21:22.503089Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"attention_masks = np.array(X_train_tokenized['attention_mask'])\nX_train = np.array(X_train_tokenized['input_ids'])\nX_test = np.array(X_test_tokenized['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:21:22.507275Z","iopub.execute_input":"2023-11-11T17:21:22.507564Z","iopub.status.idle":"2023-11-11T17:21:24.700464Z","shell.execute_reply.started":"2023-11-11T17:21:22.507537Z","shell.execute_reply":"2023-11-11T17:21:24.699559Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Define input layer for BERT model\ninput_layer = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_ids\")\n\n# Connect tokenizer output to BERT model\nbert_output = bert_model(input_layer)[0]\n\nnet = Bidirectional(LSTM(128, return_sequences=True))(bert_output)\nnet = Conv1D(128, 7, activation='relu', padding='same')(net)\nnet = MaxPooling1D()(net)\nnet = Conv1D(256, 5, activation='relu', padding='same')(net)\nnet = MaxPooling1D()(net)\nnet = Conv1D(512, 3, activation='relu', padding='same')(net)\nnet = MaxPooling1D()(net)\nnet = Flatten()(net)\nnet = Dense(128, activation='relu')(net)\nnet = Dropout(0.5)(net)\noutputs = Dense(1, activation='sigmoid')(net) \n\n# Define the model\nmodel = Model(inputs=[input_layer], outputs=[outputs])  # Fix: use 'outputs' instead of 'output_layer'\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-5), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:21:24.701821Z","iopub.execute_input":"2023-11-11T17:21:24.702147Z","iopub.status.idle":"2023-11-11T17:21:28.641421Z","shell.execute_reply.started":"2023-11-11T17:21:24.702116Z","shell.execute_reply":"2023-11-11T17:21:28.640652Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    x=X_train,\n    y=y_train,\n    validation_split=0.2,\n    epochs=5,\n    batch_size=16,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T17:21:28.642666Z","iopub.execute_input":"2023-11-11T17:21:28.643050Z","iopub.status.idle":"2023-11-11T18:08:20.361310Z","shell.execute_reply.started":"2023-11-11T17:21:28.643012Z","shell.execute_reply":"2023-11-11T18:08:20.360436Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch 1/5\n2000/2000 [==============================] - 574s 281ms/step - loss: 0.4115 - accuracy: 0.7951 - val_loss: 0.2503 - val_accuracy: 0.8953\nEpoch 2/5\n2000/2000 [==============================] - 559s 280ms/step - loss: 0.2122 - accuracy: 0.9159 - val_loss: 0.2401 - val_accuracy: 0.8984\nEpoch 3/5\n2000/2000 [==============================] - 560s 280ms/step - loss: 0.1218 - accuracy: 0.9554 - val_loss: 0.2657 - val_accuracy: 0.8996\nEpoch 4/5\n2000/2000 [==============================] - 560s 280ms/step - loss: 0.0711 - accuracy: 0.9766 - val_loss: 0.3349 - val_accuracy: 0.8960\nEpoch 5/5\n2000/2000 [==============================] - 559s 280ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.4506 - val_accuracy: 0.8967\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 16  # Set batch size to the same value as used in training\nloss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\nprint('Test accuracy:', accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T18:08:20.362753Z","iopub.execute_input":"2023-11-11T18:08:20.363227Z","iopub.status.idle":"2023-11-11T18:09:12.375780Z","shell.execute_reply.started":"2023-11-11T18:08:20.363194Z","shell.execute_reply":"2023-11-11T18:09:12.375003Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"625/625 [==============================] - 52s 83ms/step - loss: 0.4912 - accuracy: 0.8890\nTest accuracy: 0.8889999985694885\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}